{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install folium\n",
    "# запустите, если у вас не работают карты\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"/Users/artemshevchenko/Desktop/ВК/features.csv\", delimiter=\",\")\n",
    "test_data = pd.read_csv(\"/Users/artemshevchenko/Desktop/ВК/test.csv\")\n",
    "train_data = pd.read_csv('/Users/artemshevchenko/Desktop/ВК/train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор коррелированных и зависимых признаков: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала, составим матрицу корреляции признаков и отбросим высоко-коррелированные. Ниже приложен код для иллюстрации мотивации выбора границы корреляции.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "corr_matrix = features.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "threshold = 0.55\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "features.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "first_columns = features.columns[:2]\n",
    "other_columns = range(0, len(features.columns) - 2)\n",
    "new_columns = list(first_columns) + list(other_columns)\n",
    "\n",
    "features.columns = new_columns\n",
    "features\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим распределение объектов ритейла. Сразу заметим, что данные по России, а объекты в основном сконцентрированы вокруг крупных российских городов - Москвы, Санкт-Петербурга, Владивостока, Казани, Новосибирска, Омска, Ростова и прочих. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymap = folium.Map(location=[55.755825, 37.617298], zoom_start=5)\n",
    "\n",
    "for index, row in features.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    folium.Marker(location=[lat, lon], tooltip='Точка').add_to(mymap)\n",
    "\n",
    "# mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация признаков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мне неизвестно ничего по дополнительным признакам, лежащим в features, а единственные признаки, которые содержат известную мне характеристику - долгота и ширина, попробуем сгенерировать новые на их основе. В частности, мы можем считать Евклидово расстояние от каждого объекта до какой-то важной для ритейла точки - в случае с Россией это крупные мегаполисы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера, сгенерируем признак, заключащющийся в расстояния координат от Москвы, и другой в расстоянии от Питера.\n",
    "(для простоты возьмём координаты Московского Кремля - 55.751999,37.617734 и центра СПб - 59.9386, 30.3141).\n",
    "Хоть далее мы и будем обучать кластеризацию на координаты и алгоритм наверняка сам заметит, что эти города скапливают вокруг себя множество точек ритейла и добавит их в features, то эта часть нужна только в качестве примера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расстояния, будут иметь достаточно большую ошибку, если мы будем считать их классическими метриками. Пропишем функцию для подсчёта гаверсинусового расстояния между двумя точками на сфере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_moscow, lon_moscow = 55.751999, 37.617734\n",
    "lat_spb, lon_spb = 59.9386, 30.3141\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "\n",
    "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
    "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
    "\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся найденной локальной оптимальной точкой минимума функции g(n_clusters_i) = mae_i в файле features.ipynb для обучения основной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 6\n",
    "\n",
    "X = features[['lat', 'lon']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "features['cluster'] = kmeans.labels_\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster_lat, cluster_lon = cluster_centers[i]\n",
    "    # print(f\"Кластер {i+1}: средняя широта {cluster_lat}, средняя долгота {cluster_lon}\") - можно посмотреть координаы центров кластеров\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters = folium.Map(location=[55.755825, 37.617298], zoom_start=5)\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster_lat, cluster_lon = cluster_centers[i]\n",
    "    features[f'distance_to_cluster{i}'] = features.apply(lambda row: haversine(row['lat'], row['lon'], cluster_lat, cluster_lon), axis=1)\n",
    "    folium.Marker(location=[cluster_lat, cluster_lon], tooltip=f'Кластер {i+1}').add_to(map_clusters)\n",
    "    \n",
    "# map_clusters - при необходмиости можно посмотреть карту с кластерами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соеденим файл features.ipynb, дополненный сгененрированными признаками, с тестовой и тренировочной выборкой. Так как id в датасетах не соответствует друг другу и идут не по порядку, мы воспользуемся следующей идеей - из-за погрешности в типах координаты в разных датасетах могут незначительно отличаться, так что мы зафиксируем некоторый \\varepsilion такой, что если координаты train\\test_data_i будут абсолютно отличаться от координат объекта features_j менее, чем на это число, то мы будем считать, что это один и тот же объект. Границы threshold определяются как минимальные для сохранения всех исходных данных.\n",
    "\n",
    " Убедимся, что таким образом действительно происходит биекция и мы нигде не теряем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/artemshevchenko/Desktop/ВК/train.csv')\n",
    "\n",
    "threshold_distance = 0.2\n",
    "\n",
    "distances = cdist(train_data[['lat', 'lon']], features[['lat', 'lon']], metric='euclidean')\n",
    "nearest_indices = np.argmin(distances, axis=1)\n",
    "nearest_distances = np.min(distances, axis=1)\n",
    "\n",
    "merged_data_train = train_data.copy()\n",
    "merged_data_train['nearest_index'] = nearest_indices\n",
    "merged_data_train['nearest_distance'] = nearest_distances\n",
    "merged_data_train = merged_data_train[merged_data_train['nearest_distance'] < threshold_distance]\n",
    "merged_data_train = pd.merge(merged_data_train, features, left_on='nearest_index', right_index=True)\n",
    "merged_data_train = merged_data_train.drop(['nearest_index', 'nearest_distance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/Users/artemshevchenko/Desktop/ВК/test.csv\")\n",
    "\n",
    "threshold_distance = 0.55\n",
    "\n",
    "distances = cdist(test_data[['lat', 'lon']], features[['lat', 'lon']], metric='euclidean')\n",
    "nearest_indices = np.argmin(distances, axis=1)\n",
    "nearest_distances = np.min(distances, axis=1)\n",
    "\n",
    "merged_data_test = test_data.copy()\n",
    "merged_data_test['nearest_index'] = nearest_indices\n",
    "merged_data_test['nearest_distance'] = nearest_distances\n",
    "merged_data_test = merged_data_test[merged_data_test['nearest_distance'] < threshold_distance]\n",
    "merged_data_test = pd.merge(merged_data_test, features, left_on='nearest_index', right_index=True)\n",
    "merged_data_test = merged_data_test.drop(['nearest_index', 'nearest_distance'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся алгоритмом случайного леса для обучения модели. Поделим тренировочную выборку на части и попробуем сначала проанализировать результаты алгоритма с возможностью проверки реальных ззначений score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.06126545126350084\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X = merged_data_train.drop(columns=['score'], axis=1)\n",
    "y = merged_data_train['score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка достаточно хорошая - можем прогнать модель через тестовые данные и выполнить задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat_x</th>\n",
       "      <th>lon_x</th>\n",
       "      <th>score</th>\n",
       "      <th>lat_y</th>\n",
       "      <th>lon_y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>cluster</th>\n",
       "      <th>distance_to_cluster0</th>\n",
       "      <th>distance_to_cluster1</th>\n",
       "      <th>distance_to_cluster2</th>\n",
       "      <th>distance_to_cluster3</th>\n",
       "      <th>distance_to_cluster4</th>\n",
       "      <th>distance_to_cluster5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56.228300</td>\n",
       "      <td>43.945535</td>\n",
       "      <td>0.080523</td>\n",
       "      <td>56.228936</td>\n",
       "      <td>43.945563</td>\n",
       "      <td>0.142355</td>\n",
       "      <td>0.291666</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.051389</td>\n",
       "      <td>4</td>\n",
       "      <td>946.277143</td>\n",
       "      <td>375.714220</td>\n",
       "      <td>2395.375457</td>\n",
       "      <td>899.701783</td>\n",
       "      <td>290.771668</td>\n",
       "      <td>1175.696712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56.834244</td>\n",
       "      <td>53.141543</td>\n",
       "      <td>0.104424</td>\n",
       "      <td>56.834461</td>\n",
       "      <td>53.142202</td>\n",
       "      <td>0.094093</td>\n",
       "      <td>0.437761</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.055459</td>\n",
       "      <td>4</td>\n",
       "      <td>383.759443</td>\n",
       "      <td>943.206334</td>\n",
       "      <td>1828.373497</td>\n",
       "      <td>1369.599339</td>\n",
       "      <td>348.751166</td>\n",
       "      <td>1472.637583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>45.042299</td>\n",
       "      <td>41.990170</td>\n",
       "      <td>0.067615</td>\n",
       "      <td>45.042112</td>\n",
       "      <td>41.989783</td>\n",
       "      <td>0.151723</td>\n",
       "      <td>0.388125</td>\n",
       "      <td>0.178486</td>\n",
       "      <td>0.020507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.077430</td>\n",
       "      <td>5</td>\n",
       "      <td>1725.932406</td>\n",
       "      <td>1185.849973</td>\n",
       "      <td>3045.531823</td>\n",
       "      <td>1825.596132</td>\n",
       "      <td>1221.106389</td>\n",
       "      <td>95.670085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59.849408</td>\n",
       "      <td>30.387762</td>\n",
       "      <td>0.088038</td>\n",
       "      <td>59.848909</td>\n",
       "      <td>30.387232</td>\n",
       "      <td>0.423663</td>\n",
       "      <td>0.570066</td>\n",
       "      <td>0.157089</td>\n",
       "      <td>0.032190</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.050685</td>\n",
       "      <td>3</td>\n",
       "      <td>1736.078711</td>\n",
       "      <td>672.848492</td>\n",
       "      <td>3086.054768</td>\n",
       "      <td>8.216297</td>\n",
       "      <td>1176.930648</td>\n",
       "      <td>1724.248252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>59.839643</td>\n",
       "      <td>30.304308</td>\n",
       "      <td>0.099686</td>\n",
       "      <td>59.839632</td>\n",
       "      <td>30.304086</td>\n",
       "      <td>0.489140</td>\n",
       "      <td>0.527301</td>\n",
       "      <td>0.118082</td>\n",
       "      <td>0.118855</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.059898</td>\n",
       "      <td>3</td>\n",
       "      <td>1740.705301</td>\n",
       "      <td>675.508023</td>\n",
       "      <td>3090.812095</td>\n",
       "      <td>5.686096</td>\n",
       "      <td>1181.043355</td>\n",
       "      <td>1725.667373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>3077</td>\n",
       "      <td>51.500685</td>\n",
       "      <td>45.951897</td>\n",
       "      <td>0.099876</td>\n",
       "      <td>51.500685</td>\n",
       "      <td>45.951860</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>0.172172</td>\n",
       "      <td>0.097444</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>4</td>\n",
       "      <td>1012.574722</td>\n",
       "      <td>677.232974</td>\n",
       "      <td>2433.695828</td>\n",
       "      <td>1348.909486</td>\n",
       "      <td>446.552620</td>\n",
       "      <td>719.774546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>3079</td>\n",
       "      <td>55.674584</td>\n",
       "      <td>37.279505</td>\n",
       "      <td>0.531557</td>\n",
       "      <td>55.673937</td>\n",
       "      <td>37.279167</td>\n",
       "      <td>0.628328</td>\n",
       "      <td>0.421714</td>\n",
       "      <td>0.142870</td>\n",
       "      <td>0.027980</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.063838</td>\n",
       "      <td>1</td>\n",
       "      <td>1365.701857</td>\n",
       "      <td>59.239577</td>\n",
       "      <td>2812.047844</td>\n",
       "      <td>625.856965</td>\n",
       "      <td>693.438635</td>\n",
       "      <td>1136.541093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>3080</td>\n",
       "      <td>55.784909</td>\n",
       "      <td>49.188791</td>\n",
       "      <td>0.101631</td>\n",
       "      <td>55.785428</td>\n",
       "      <td>49.188083</td>\n",
       "      <td>0.193135</td>\n",
       "      <td>0.452026</td>\n",
       "      <td>0.163252</td>\n",
       "      <td>0.025054</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.051499</td>\n",
       "      <td>4</td>\n",
       "      <td>628.054589</td>\n",
       "      <td>696.710890</td>\n",
       "      <td>2086.844167</td>\n",
       "      <td>1204.391119</td>\n",
       "      <td>81.233515</td>\n",
       "      <td>1239.473881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>3081</td>\n",
       "      <td>55.118828</td>\n",
       "      <td>61.462996</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>55.118176</td>\n",
       "      <td>61.462914</td>\n",
       "      <td>0.127627</td>\n",
       "      <td>0.465737</td>\n",
       "      <td>0.158460</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.070415</td>\n",
       "      <td>0</td>\n",
       "      <td>178.674001</td>\n",
       "      <td>1473.220575</td>\n",
       "      <td>1335.265543</td>\n",
       "      <td>1917.878387</td>\n",
       "      <td>836.229913</td>\n",
       "      <td>1751.554111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>3083</td>\n",
       "      <td>56.317263</td>\n",
       "      <td>43.887981</td>\n",
       "      <td>0.137444</td>\n",
       "      <td>56.317392</td>\n",
       "      <td>43.887978</td>\n",
       "      <td>0.102848</td>\n",
       "      <td>0.508481</td>\n",
       "      <td>0.161901</td>\n",
       "      <td>0.065573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.044016</td>\n",
       "      <td>4</td>\n",
       "      <td>948.870934</td>\n",
       "      <td>374.331747</td>\n",
       "      <td>2396.684855</td>\n",
       "      <td>891.444175</td>\n",
       "      <td>297.536469</td>\n",
       "      <td>1184.790386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3084 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      lat_x      lon_x     score      lat_y      lon_y         0  \\\n",
       "0        0  56.228300  43.945535  0.080523  56.228936  43.945563  0.142355   \n",
       "1        1  56.834244  53.141543  0.104424  56.834461  53.142202  0.094093   \n",
       "2        2  45.042299  41.990170  0.067615  45.042112  41.989783  0.151723   \n",
       "3        3  59.849408  30.387762  0.088038  59.848909  30.387232  0.423663   \n",
       "4        4  59.839643  30.304308  0.099686  59.839632  30.304086  0.489140   \n",
       "...    ...        ...        ...       ...        ...        ...       ...   \n",
       "3077  3077  51.500685  45.951897  0.099876  51.500685  45.951860  0.033270   \n",
       "3079  3079  55.674584  37.279505  0.531557  55.673937  37.279167  0.628328   \n",
       "3080  3080  55.784909  49.188791  0.101631  55.785428  49.188083  0.193135   \n",
       "3081  3081  55.118828  61.462996  0.125265  55.118176  61.462914  0.127627   \n",
       "3083  3083  56.317263  43.887981  0.137444  56.317392  43.887978  0.102848   \n",
       "\n",
       "             1         2         3  ...   20        21        22  cluster  \\\n",
       "0     0.291666  0.112751  0.010147  ...  1.0  0.454545  0.051389        4   \n",
       "1     0.437761  0.106110  0.056220  ...  1.0  0.454545  0.055459        4   \n",
       "2     0.388125  0.178486  0.020507  ...  1.0  0.454545  0.077430        5   \n",
       "3     0.570066  0.157089  0.032190  ...  1.0  0.454545  0.050685        3   \n",
       "4     0.527301  0.118082  0.118855  ...  1.0  0.454545  0.059898        3   \n",
       "...        ...       ...       ...  ...  ...       ...       ...      ...   \n",
       "3077  0.172172  0.097444  0.054565  ...  1.0  0.454545  0.055855        4   \n",
       "3079  0.421714  0.142870  0.027980  ...  1.0  0.454545  0.063838        1   \n",
       "3080  0.452026  0.163252  0.025054  ...  1.0  0.454545  0.051499        4   \n",
       "3081  0.465737  0.158460  0.033000  ...  1.0  0.454545  0.070415        0   \n",
       "3083  0.508481  0.161901  0.065573  ...  1.0  0.454545  0.044016        4   \n",
       "\n",
       "      distance_to_cluster0  distance_to_cluster1  distance_to_cluster2  \\\n",
       "0               946.277143            375.714220           2395.375457   \n",
       "1               383.759443            943.206334           1828.373497   \n",
       "2              1725.932406           1185.849973           3045.531823   \n",
       "3              1736.078711            672.848492           3086.054768   \n",
       "4              1740.705301            675.508023           3090.812095   \n",
       "...                    ...                   ...                   ...   \n",
       "3077           1012.574722            677.232974           2433.695828   \n",
       "3079           1365.701857             59.239577           2812.047844   \n",
       "3080            628.054589            696.710890           2086.844167   \n",
       "3081            178.674001           1473.220575           1335.265543   \n",
       "3083            948.870934            374.331747           2396.684855   \n",
       "\n",
       "      distance_to_cluster3  distance_to_cluster4  distance_to_cluster5  \n",
       "0               899.701783            290.771668           1175.696712  \n",
       "1              1369.599339            348.751166           1472.637583  \n",
       "2              1825.596132           1221.106389             95.670085  \n",
       "3                 8.216297           1176.930648           1724.248252  \n",
       "4                 5.686096           1181.043355           1725.667373  \n",
       "...                    ...                   ...                   ...  \n",
       "3077           1348.909486            446.552620            719.774546  \n",
       "3079            625.856965            693.438635           1136.541093  \n",
       "3080           1204.391119             81.233515           1239.473881  \n",
       "3081           1917.878387            836.229913           1751.554111  \n",
       "3083            891.444175            297.536469           1184.790386  \n",
       "\n",
       "[3084 rows x 36 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_score = merged_data_train[\"score\"]\n",
    "merged_data_train = merged_data_train.drop([\"score\"], axis=1)\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(merged_data_train, train_score)\n",
    "\n",
    "predictions = model.predict(merged_data_test)\n",
    "\n",
    "res = pd.DataFrame(predictions)\n",
    "res[\"id\"] = merged_data_test[\"id\"]\n",
    "res = res[['id', 0]]\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на случай, если на вашем ядре не работает следующая клетка и импорт solution.py: просто раскомментируйте этот кусок\n",
    "# и запустите последний блок для сохранения предсказаний в файл\n",
    "\n",
    "# def save_predictions_to_csv(model, test_data, features, output_path):\n",
    "    \n",
    "#     distances = cdist(test_data[['lat', 'lon']], features[['lat', 'lon']], metric='euclidean')\n",
    "#     nearest_indices = np.argmin(distances, axis=1)\n",
    "#     nearest_distances = np.min(distances, axis=1)\n",
    "\n",
    "#     merged_data_test = test_data.copy()\n",
    "#     merged_data_test['nearest_index'] = nearest_indices\n",
    "#     merged_data_test['nearest_distance'] = nearest_distances\n",
    "#     merged_data_test = merged_data_test[merged_data_test['nearest_distance'] < 0.5]\n",
    "#     merged_data_test = pd.merge(merged_data_test, features, left_on='nearest_index', right_index=True)\n",
    "#     merged_data_test = merged_data_test.drop(['nearest_index', 'nearest_distance'], axis=1)\n",
    "\n",
    "#     predictions = model.predict(merged_data_test)\n",
    "#     res = pd.DataFrame(predictions)\n",
    "#     res[\"id\"] = merged_data_test[\"id\"]\n",
    "#     res = res[['id', 0]]\n",
    "#     res = res.rename(columns={0: \"score\"})\n",
    "\n",
    "#     res.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artemshevchenko/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "save_predictions_to_csv(model, test_data, features, \"/Users/artemshevchenko/Desktop/ВК/submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
